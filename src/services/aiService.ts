type SummOpts = { 
  lang?: string
  type?: 'tldr' | 'key-points' | 'teaser' | 'headline'  // æ‘˜è¦ç±»å‹
  onChunk?: (chunk: string) => void  // æµå¼æ›´æ–°å›è°ƒ
}
type ExplainOpts = { 
  context?: string
  lang?: string
  onChunk?: (chunk: string) => void  // æµå¼æ›´æ–°å›è°ƒ
}
type TransOpts = { 
  targetLang: string
  onChunk?: (chunk: string) => void  // æµå¼æ›´æ–°å›è°ƒ
}

// ç±»å‹å£°æ˜ - Chrome Summarizer API (æœ€æ–°ç‰ˆæœ¬)
declare global {
  // å…¨å±€ Summarizer ç±»
  const Summarizer: {
    availability(): Promise<'unavailable' | 'downloadable' | 'downloading' | 'available'>
    create(options?: SummarizerCreateOptions): Promise<Summarizer>
  }

  interface SummarizerCreateOptions {
    sharedContext?: string
    type?: 'tldr' | 'key-points' | 'teaser' | 'headline'
    length?: 'short' | 'medium' | 'long'
    format?: 'plain-text' | 'markdown'
    expectedInputLanguages?: string[]
    outputLanguage?: string
    monitor?: (m: AIDownloadProgressMonitor) => void
  }

  interface AIDownloadProgressMonitor {
    addEventListener(type: 'downloadprogress', listener: (e: DownloadProgressEvent) => void): void
  }

  interface DownloadProgressEvent {
    loaded: number
    total: number
  }

  interface Summarizer {
    summarize(text: string, options?: { context?: string }): Promise<string>
    summarizeStreaming(text: string, options?: { context?: string }): AsyncIterable<string>
    destroy(): void
  }

  // å…¨å±€ Translator ç±»
  const Translator: {
    availability(options: { sourceLanguage: string; targetLanguage: string }): Promise<'unavailable' | 'downloadable' | 'downloading' | 'available'>
    create(options: TranslatorCreateOptions): Promise<Translator>
  }

  interface TranslatorCreateOptions {
    sourceLanguage: string
    targetLanguage: string
    monitor?: (m: AIDownloadProgressMonitor) => void
  }

  interface Translator {
    translate(text: string): Promise<string>
    translateStreaming(text: string): AsyncIterable<string>
    destroy(): void
  }

  // å…¨å±€ LanguageDetector ç±»
  const LanguageDetector: {
    availability(): Promise<'unavailable' | 'downloadable' | 'downloading' | 'available'>
    create(options?: LanguageDetectorCreateOptions): Promise<LanguageDetector>
  }

  interface LanguageDetectorCreateOptions {
    monitor?: (m: AIDownloadProgressMonitor) => void
  }

  interface LanguageDetector {
    detect(text: string): Promise<LanguageDetectionResult[]>
    destroy(): void
  }

  interface LanguageDetectionResult {
    detectedLanguage: string
    confidence: number
  }

  // å…¨å±€ LanguageModel ç±» (Prompt API)
  const LanguageModel: {
    availability(): Promise<'unavailable' | 'downloadable' | 'downloading' | 'available'>
    create(options?: LanguageModelCreateOptions): Promise<LanguageModelSession>
    params(): Promise<LanguageModelParams>
  }

  interface LanguageModelParams {
    defaultTopK: number
    maxTopK: number
    defaultTemperature: number
    maxTemperature: number
  }

  interface LanguageModelCreateOptions {
    signal?: AbortSignal
    monitor?: (m: AIDownloadProgressMonitor) => void
    systemPrompt?: string
    initialPrompts?: LanguageModelPrompt[]
    topK?: number
    temperature?: number
    expectedInputs?: Array<{ type: 'text' | 'image' | 'audio'; languages?: string[] }>
    expectedOutputs?: Array<{ type: 'text'; languages?: string[] }>
  }

  interface LanguageModelPrompt {
    role: 'system' | 'user' | 'assistant'
    content: string
    prefix?: boolean
  }

  interface LanguageModelSession {
    prompt(input: string, options?: { signal?: AbortSignal }): Promise<string>
    promptStreaming(input: string, options?: { signal?: AbortSignal }): AsyncIterable<string>
    destroy(): void
    clone(options?: { signal?: AbortSignal }): Promise<LanguageModelSession>
    inputUsage: number
    inputQuota: number
  }
}

// Summarizer å®ä¾‹ç¼“å­˜ï¼ˆæŒ‰ type åˆ†åˆ«ç¼“å­˜ï¼‰
const summarizerCache: Map<string, Summarizer> = new Map()

// LanguageDetector å®ä¾‹ç¼“å­˜
let languageDetectorInstance: LanguageDetector | null = null

// Translator å®ä¾‹ç¼“å­˜ï¼ˆæŒ‰è¯­è¨€å¯¹ç¼“å­˜ï¼‰
const translatorCache: Map<string, Translator> = new Map()

// LanguageModel å®ä¾‹ç¼“å­˜ï¼ˆç”¨äº explain åŠŸèƒ½ï¼‰
// æ³¨æ„ï¼šexplain æ˜¯å•æ¬¡å¯¹è¯ï¼Œsession ç”¨å®Œå³é”€æ¯ï¼Œä¸éœ€è¦æŒä¹…ç¼“å­˜
let currentExplainSession: LanguageModelSession | null = null
let currentExplainAbortController: AbortController | null = null

// Summarize å’Œ Translate çš„ä¸­æ­¢æ ‡å¿—ï¼ˆç”¨äºç»ˆæ­¢æµå¼ç”Ÿæˆï¼‰
let shouldAbortSummarize = false
let shouldAbortTranslate = false

// Keepalive session - ä¿æŒæ¨¡å‹ loadedï¼Œé¿å…æ¯æ¬¡éƒ½é‡æ–°åŠ è½½
// æ ¹æ® best practiceï¼šç©º session å ç”¨å†…å­˜å°‘ï¼Œä½†èƒ½ä¿æŒæ¨¡å‹ ready
let keepaliveSession: LanguageModelSession | null = null

// æ£€æŸ¥ Summarizer API æ˜¯å¦å¯ç”¨
async function checkSummarizerAvailability(): Promise<'available' | 'needs-download' | 'unavailable'> {
  try {
    // æ£€æŸ¥ API æ˜¯å¦å­˜åœ¨
    console.log('[AI] Checking Summarizer API...')
    
    if (!('Summarizer' in self)) {
      console.log('[AI] âŒ Summarizer API not found')
      console.log('[AI] ğŸ’¡ Make sure you have:')
      console.log('[AI]    1. Chrome 138+ stable (or Chrome Canary/Dev 128+)')
      console.log('[AI]    2. Enabled flags in chrome://flags:')
      console.log('[AI]       - #summarization-api-for-gemini-nano')
      console.log('[AI]       - #optimization-guide-on-device-model')
      return 'unavailable'
    }
    
    console.log('[AI] âœ… Summarizer API found')
    
    // æ£€æŸ¥å¯ç”¨æ€§
    const status = await Summarizer.availability()
    console.log('[AI] Summarizer status:', status)
    
    if (status === 'unavailable') {
      console.log('[AI] âŒ Summarizer unavailable (device not supported)')
      return 'unavailable'
    }
    
    if (status === 'downloadable') {
      console.log('[AI] â³ Model needs download (will auto-download on create())')
      return 'needs-download'
    }
    
    if (status === 'downloading') {
      console.log('[AI] â³ Model is downloading...')
      return 'needs-download'
    }
    
    console.log('[AI] âœ… Summarizer ready!')
    return 'available'
  } catch (e) {
    console.warn('[AI] âŒ Error checking availability:', e)
    return 'unavailable'
  }
}

// æ ¹æ®æ–‡æœ¬é•¿åº¦è‡ªåŠ¨é€‰æ‹©æ‘˜è¦é•¿åº¦
function determineLength(text: string): 'short' | 'medium' | 'long' {
  const wordCount = text.split(/\s+/).length
  
  if (wordCount < 200) return 'short'      // çŸ­æ–‡æœ¬: <200è¯ -> 1å¥æ‘˜è¦
  if (wordCount < 800) return 'medium'     // ä¸­ç­‰æ–‡æœ¬: 200-800è¯ -> 3å¥æ‘˜è¦
  return 'long'                            // é•¿æ–‡æœ¬: >800è¯ -> 5å¥æ‘˜è¦
}

// è·å–æˆ–åˆ›å»º Summarizer å®ä¾‹
async function getSummarizer(text: string, opts: SummOpts = {}): Promise<Summarizer | null> {
  try {
    const requestedLang = opts.lang || 'en'
    const type = opts.type || 'tldr'

    // ä»…å…è®¸ Summarizer æ”¯æŒçš„è¾“å‡ºè¯­è¨€ï¼Œå…¶ä»–ä¸€å¾‹å›é€€åˆ° en
    const supportedOutputLangs = ['en', 'es', 'ja'] as const
    const outputLanguage = (supportedOutputLangs as readonly string[]).includes(requestedLang) ? requestedLang : 'en'

    // ç¼“å­˜é”®éœ€è¦åŒ…å«è¾“å‡ºè¯­è¨€ï¼Œé¿å…å¤ç”¨åˆ°ä¸åŒè¯­è¨€é…ç½®çš„å®ä¾‹
    const cacheKey = `${type}:${outputLanguage}`
    
    // å¦‚æœå·²æœ‰è¯¥ç±»å‹çš„å®ä¾‹ï¼Œç›´æ¥è¿”å›
    if (summarizerCache.has(cacheKey)) {
      console.log(`[AI] Reusing cached Summarizer (type: ${type})`)
      return summarizerCache.get(cacheKey)!
    }

    // æ£€æŸ¥å¯ç”¨æ€§
    const availability = await checkSummarizerAvailability()
    if (availability === 'unavailable') {
      return null
    }

    // æ£€æŸ¥ç”¨æˆ·æ¿€æ´»ï¼ˆé¦–æ¬¡ä¸‹è½½æ¨¡å‹æ—¶éœ€è¦ï¼‰
    if (availability === 'needs-download' && !navigator.userActivation.isActive) {
      console.log('[AI] âš ï¸ Model download requires user activation')
      return null
    }
    
    // åˆ›å»ºé…ç½®
    const summaryType = opts.type || 'tldr'
    const createOptions: SummarizerCreateOptions = {
      sharedContext: 'General purpose user-friendly text summarization for web content',
      type: summaryType,
      length: determineLength(text),
      format: summaryType === 'key-points' ? 'markdown' : 'plain-text',
      outputLanguage : outputLanguage,
      expectedInputLanguages: ['en', 'ja', 'es']
    }
    
    // åªæœ‰éœ€è¦ä¸‹è½½æ—¶æ‰æ·»åŠ  monitor
    if (availability === 'needs-download') {
      console.log('[AI] Model needs download - adding progress monitor')
      createOptions.monitor = (m) => {
        m.addEventListener('downloadprogress', (e) => {
          const percent = Math.round(e.loaded * 100)
          console.log(`[AI] Downloading model: ${percent}%`)
        })
      }
    } else {
      console.log('[AI] Model already available - no download needed')
    }

    console.log('[AI] Creating Summarizer instance...')
    console.log('[AI] Config:', {
      type: createOptions.type,
      length: createOptions.length,
      format: createOptions.format,
      wordCount: text.split(/\s+/).length,
      outputLanguage: createOptions.outputLanguage
    })
    
    const summarizer = await Summarizer.create(createOptions)
    console.log('[AI] âœ… Summarizer created successfully')
    
    // ç¼“å­˜è¯¥å®ä¾‹
    summarizerCache.set(cacheKey, summarizer)
    console.log(`[AI] Cached Summarizer (type: ${type})`)

    return summarizer
  } catch (e) {
    console.error('[AI] âŒ Failed to create Summarizer:', e)
    return null
  }
}

// é™çº§æ–¹æ¡ˆï¼šç®€å•æ–‡æœ¬æ‘˜è¦
function fallbackSummarize(text: string): string {
  const MAX_WORDS = 150
  const words = text.split(/\s+/)
  const truncated = words.slice(0, MAX_WORDS).join(' ')
  const troubleshooting = `

âš ï¸ Summarization unavailable - AI model not ready. Please refresh the page and try again later.

Quick Setup Guide:
1. Use Chrome 138+ or Chrome Canary/Dev (chrome://version)
2. Enable flags in chrome://flags:
   â€¢ #summarization-api-for-gemini-nano â†’ Enabled Multilingual
   â€¢ #optimization-guide-on-device-model â†’ Enabled BypassPerfRequirement
3. Restart browser
4. Download model at chrome://components (Optimization Guide On Device Model)
5. Requirements: 22GB disk space, 4GB+ GPU or 16GB+ RAM

Learn more: https://developer.chrome.com/docs/ai/built-in-apis`
  
  return truncated + (words.length > MAX_WORDS ? '...' : '') + troubleshooting
}

export async function summarize(text: string, opts: SummOpts = {}): Promise<string> {
  // é‡ç½®ä¸­æ­¢æ ‡å¿—
  shouldAbortSummarize = false
  
  // ç¡®ä¿è¯­è¨€å’Œç±»å‹å‚æ•°æœ‰é»˜è®¤å€¼
  const optsWithDefaults: SummOpts = {
    lang: 'en',
    type: 'tldr',  // é»˜è®¤ tldr
    ...opts  // è°ƒç”¨æ—¶ä¼ é€’çš„ opts ä¼šè¦†ç›–é»˜è®¤å€¼
  }
  
  // æ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼ˆè‡³å°‘10ä¸ªè¯ï¼‰
  const wordCount = text.trim().split(/\s+/).length
  if (wordCount < 10) {
    const warningMsg = 'âš ï¸ Selected content is too short for summarization. Please select at least 10 words.'
    console.warn('[AI] âŒ Text too short for summarization: only', wordCount, 'words')
    optsWithDefaults.onChunk?.(warningMsg)
    return warningMsg
  }
  
  try {
    // å°è¯•ä½¿ç”¨ Chrome AI Summarizer API
    const summarizer = await getSummarizer(text, optsWithDefaults)
    
    if (summarizer) {
      console.log('[AI] Using Chrome AI Summarizer API (streaming)')
      
      try {
        // ä½¿ç”¨æµå¼ API - å®˜æ–¹æ¨èçš„ for await of è¯­æ³•
        const stream = summarizer.summarizeStreaming(text)
        let result = ''
        
        for await (const chunk of stream) {
          // æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»ˆæ­¢
          if (shouldAbortSummarize) {
            console.log('[AI] Summarize was aborted')
            return ''
          }
          
          // æ¯ä¸ª chunk æ˜¯å¢é‡å†…å®¹ï¼ˆæ–°å¢çš„ tokenï¼‰ï¼Œéœ€è¦ç´¯ç§¯
          result += chunk
          
          // å¦‚æœæœ‰å›è°ƒï¼Œå®æ—¶æ›´æ–°ç´¯ç§¯ç»“æœ
          if (optsWithDefaults.onChunk) {
            optsWithDefaults.onChunk(result)
          }
        }
        
        console.log(`[AI] âœ… Streaming completed`)
        return result
      } catch (streamError) {
        console.error('[AI] Streaming error, trying non-streaming approach:', streamError)
        
        // å¦‚æœå·²ç»è¢«ç»ˆæ­¢ï¼Œç›´æ¥è¿”å›
        if (shouldAbortSummarize) {
          console.log('[AI] Summarize was aborted')
          return ''
        }
        
        // å¦‚æœæµå¼å¤±è´¥ï¼Œå°è¯•æ‰¹é‡æ¨¡å¼
        const result = await summarizer.summarize(text)
        optsWithDefaults.onChunk?.(result)
        return result
      }
    }
    
    // é™çº§åˆ°ç®€å•æ‘˜è¦
    console.log('[AI] Using fallback summarization')
    const fallback = fallbackSummarize(text)
    optsWithDefaults.onChunk?.(fallback)
    return fallback
  } catch (e) {
    console.error('[AI] Summarization error:', e)
    const fallback = fallbackSummarize(text)
    optsWithDefaults.onChunk?.(fallback)
    return fallback
  }
}

// æ£€æŸ¥ LanguageModel (Prompt API) æ˜¯å¦å¯ç”¨
async function checkLanguageModelAvailability(): Promise<'available' | 'needs-download' | 'unavailable'> {
  try {
    console.log('[AI] Checking LanguageModel API...')
    
    if (!('LanguageModel' in self)) {
      console.log('[AI] âŒ LanguageModel API not found')
      console.log('[AI] ğŸ’¡ Make sure you have:')
      console.log('[AI]    1. Chrome 128+ (Canary/Dev) or Chrome 138+ (Stable)')
      console.log('[AI]    2. Enabled flags in chrome://flags:')
      console.log('[AI]       - #prompt-api-for-gemini-nano')
      console.log('[AI]       - #optimization-guide-on-device-model')
      return 'unavailable'
    }
    
    console.log('[AI] âœ… LanguageModel API found')
    
    // æ£€æŸ¥å¯ç”¨æ€§
    const status = await LanguageModel.availability()
    console.log('[AI] LanguageModel status:', status)
    
    if (status === 'unavailable') {
      console.log('[AI] âŒ LanguageModel unavailable (device not supported)')
      return 'unavailable'
    }
    
    if (status === 'downloadable') {
      console.log('[AI] â³ Model needs download (will auto-download on create())')
      return 'needs-download'
    }
    
    if (status === 'downloading') {
      console.log('[AI] â³ Model is downloading...')
      return 'needs-download'
    }
    
    console.log('[AI] âœ… LanguageModel ready!')
    return 'available'
  } catch (e) {
    console.warn('[AI] âŒ Error checking LanguageModel availability:', e)
    return 'unavailable'
  }
}

// åˆ›å»º keepalive session ä¿æŒæ¨¡å‹ ready
// å¯¼å‡ºä»¥ä¾¿ content script å¯ä»¥åœ¨é¡µé¢åŠ è½½æ—¶è°ƒç”¨
export async function ensureKeepaliveSession() {
  try {
    // å¦‚æœå·²æœ‰ keepalive sessionï¼Œç›´æ¥è¿”å›
    if (keepaliveSession) {
      console.log('[AI] Keepalive session already exists')
      return
    }
    
    // å…ˆæ£€æŸ¥å¯ç”¨æ€§
    const availability = await checkLanguageModelAvailability()
    if (availability === 'unavailable') {
      console.log('[AI] Cannot create keepalive session - model unavailable')
      return
    }
    
    console.log('[AI] Creating keepalive session to keep model ready...')
    
    // åˆ›å»ºä¸€ä¸ªæœ€å°é…ç½®çš„ session
    // ä½¿ç”¨ä¸ explain ç›¸åŒçš„ expectedInputs/expectedOutputs ä»¥ç¡®ä¿ä¸€è‡´æ€§
    keepaliveSession = await LanguageModel.create({
      topK: 1,
      temperature: 1,
      expectedInputs: [
        { type: 'text', languages: ['en', 'ja', 'es'] }
      ],
      expectedOutputs: [
        { type: 'text', languages: ['en', 'ja', 'es'] }
      ]
    })
    
    console.log('[AI] âœ… Keepalive session created - model stays ready')
  } catch (e) {
    console.warn('[AI] Failed to create keepalive session:', e)
  }
}

// é”€æ¯ keepalive session
function destroyKeepaliveSession() {
  try {
    if (keepaliveSession) {
      keepaliveSession.destroy()
      keepaliveSession = null
      console.log('[AI] Keepalive session destroyed')
    }
  } catch (e) {
    console.warn('[AI] Error destroying keepalive session:', e)
  }
}

// æ¸…ç†å½“å‰çš„ explain session
export function destroyExplainSession() {
  try {
    // å¦‚æœæœ‰æ­£åœ¨è¿›è¡Œçš„è¯·æ±‚ï¼Œå…ˆ abort
    if (currentExplainAbortController) {
      currentExplainAbortController.abort()
      currentExplainAbortController = null
      console.log('[AI] Aborted ongoing explain request')
    }
    
    // é”€æ¯ session
    if (currentExplainSession) {
      currentExplainSession.destroy()
      currentExplainSession = null
      console.log('[AI] Explain session destroyed')
    }
  } catch (e) {
    console.warn('[AI] Error destroying explain session:', e)
  }
}

// ç»ˆæ­¢å½“å‰çš„ summarize æ“ä½œ
export function abortSummarize() {
  shouldAbortSummarize = true
  console.log('[AI] Requested to abort summarize')
}

// ç»ˆæ­¢å½“å‰çš„ translate æ“ä½œ
export function abortTranslate() {
  shouldAbortTranslate = true
  console.log('[AI] Requested to abort translate')
}

// æ¸…ç†è¾“å…¥æ–‡æœ¬ï¼Œé˜²æ­¢æ¨¡å‹æŠ¥é”™
function cleanTextInput(text: string): string {
  // ç§»é™¤è¿‡å¤šçš„ç©ºç™½å’Œç‰¹æ®Šå­—ç¬¦
  return text
    .replace(/\s+/g, ' ')  // å¤šä¸ªç©ºç™½ç¬¦æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
    .replace(/[\x00-\x1F\x7F-\x9F]/g, '')  // ç§»é™¤æ§åˆ¶å­—ç¬¦
    .trim()
    .slice(0, 2000)  // é™åˆ¶é•¿åº¦ï¼Œé¿å…è¶…å‡º quota
}

// é™çº§æ–¹æ¡ˆï¼šç®€å•è§£é‡Š
function fallbackExplain(term: string, context?: string): string {
  const ctx = context?.slice(0, 300) ?? ''
  const troubleshooting = `

âš ï¸ Explanation unavailable - AI model not ready. Please refresh the page and try again later.

Quick Setup Guide:
1. Use Chrome 138+ or Chrome Canary/Dev (chrome://version)
2. Enable flags in chrome://flags:
   â€¢ #prompt-api-for-gemini-nano â†’ Enabled Multilingual
   â€¢ #optimization-guide-on-device-model â†’ Enabled BypassPerfRequirement
3. Restart browser
4. Download model at chrome://components (Optimization Guide On Device Model)
5. Requirements: 22GB disk space, 4GB+ GPU or 16GB+ RAM

Learn more: https://developer.chrome.com/docs/ai/built-in-apis`
  
  return `"${term}"${ctx ? ` - Context: ${ctx}...` : ''}${troubleshooting}`
}

export async function explain(term: string, opts: ExplainOpts = {}): Promise<string> {
  // å…ˆæ¸…ç†ä¹‹å‰çš„ sessionï¼ˆå¦‚æœæœ‰ï¼‰
  destroyExplainSession()
  
  const optsWithDefaults: ExplainOpts = {
    lang: 'en',
    ...opts
  }
  
  try {
    console.log('[AI] ===== Explain Request =====')
    console.log('[AI] Term:', term)
    console.log('[AI] Output language:', optsWithDefaults.lang)
    
    // æ¸…ç†è¾“å…¥
    const cleanedTerm = cleanTextInput(term)
    
    // æ£€æŸ¥æ¸…ç†åçš„å†…å®¹é•¿åº¦
    if (cleanedTerm.length < 3) {
      const errorMsg = 'âš ï¸ Selected content is too short or invalid. Please select something else and try again.'
      console.warn('[AI] âŒ Invalid input: cleaned term length =', cleanedTerm.length)
      console.warn('[AI] Original term:', term)
      console.warn('[AI] Cleaned term:', cleanedTerm)
      optsWithDefaults.onChunk?.(errorMsg)
      return errorMsg
    }
    
    const cleanedContext = opts.context ? cleanTextInput(opts.context) : ''
    
    // æ£€æŸ¥å¯ç”¨æ€§
    const availability = await checkLanguageModelAvailability()
    if (availability === 'unavailable') {
      const fallback = fallbackExplain(term, opts.context)
      optsWithDefaults.onChunk?.(fallback)
      return fallback
    }
    
    // æ£€æŸ¥ç”¨æˆ·æ¿€æ´»ï¼ˆé¦–æ¬¡ä¸‹è½½æ¨¡å‹æ—¶éœ€è¦ï¼‰
    if (availability === 'needs-download' && !navigator.userActivation.isActive) {
      console.log('[AI] âš ï¸ Model download requires user activation')
      const fallback = fallbackExplain(term, opts.context)
      optsWithDefaults.onChunk?.(fallback)
      return fallback
    }
    
    // å¦‚æœæœ‰ keepalive sessionï¼Œé”€æ¯å®ƒä¸ºæ–° session è…¾å‡ºèµ„æº
    if (keepaliveSession) {
      console.log('[AI] Destroying keepalive session to make room for explain session')
      destroyKeepaliveSession()
      // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©èµ„æºé‡Šæ”¾
      await new Promise(resolve => setTimeout(resolve, 50))
    }
    
    // åˆ›å»º AbortController
    currentExplainAbortController = new AbortController()
    
    // è·å–é»˜è®¤å‚æ•°
    const params = await LanguageModel.params()
    console.log('[AI] Model params:', params)
    
    // æ„å»º system promptï¼ˆå¼•å¯¼æ¨¡å‹è¾“å‡ºä¸è¶…è¿‡3å¥è¯çš„ç®€æ´è§£é‡Šï¼‰
    const systemPrompt = `You are a helpful assistant that explains terms and concepts clearly and concisely. 
Always provide explanations in exactly 3 sentences or less. 
Be accurate, helpful, and consider the context provided.
Output language: ${optsWithDefaults.lang}.`
    
    // æ„å»º user prompt
    let userPrompt = `Explain: "${cleanedTerm}"`
    if (cleanedContext) {
      userPrompt += `\n\nContext: ${cleanedContext}`
    }
    userPrompt += `\n\nProvide a clear, concise explanation in ${optsWithDefaults.lang} (maximum 3 sentences).`
    
    console.log('[AI] User prompt:', userPrompt)
    
    // åˆ›å»ºé…ç½®
    const createOptions: LanguageModelCreateOptions = {
      signal: currentExplainAbortController.signal,
      topK: params.defaultTopK,
      temperature: params.defaultTemperature,
      initialPrompts: [
        { role: 'system', content: systemPrompt }
      ],
      expectedInputs: [
        { type: 'text', languages: ['en', 'ja', 'es'] }
      ],
      expectedOutputs: [
        { type: 'text', languages: [optsWithDefaults.lang || 'en'] }
      ]
    }
    
    // åªæœ‰éœ€è¦ä¸‹è½½æ—¶æ‰æ·»åŠ  monitor
    if (availability === 'needs-download') {
      console.log('[AI] Model needs download - adding progress monitor')
      createOptions.monitor = (m) => {
        m.addEventListener('downloadprogress', (e) => {
          const percent = Math.round(e.loaded * 100)
          console.log(`[AI] Downloading model: ${percent}%`)
        })
      }
    }
    
    console.log('[AI] Creating LanguageModel session...')
    currentExplainSession = await LanguageModel.create(createOptions)
    
    // éªŒè¯ session åˆ›å»ºæˆåŠŸ
    if (!currentExplainSession) {
      console.error('[AI] âŒ Failed to create session - returned null')
      const fallback = fallbackExplain(term, opts.context)
      optsWithDefaults.onChunk?.(fallback)
      return fallback
    }
    
    console.log('[AI] âœ… Session created successfully')
    
    // ä½¿ç”¨æµå¼ API - å®˜æ–¹æ¨èçš„ for await of è¯­æ³•ï¼ˆä¸ summarizer/translator ä¸€è‡´ï¼‰
    console.log('[AI] Starting streaming explanation...')
    
    try {
      const stream = currentExplainSession.promptStreaming(userPrompt, {
        signal: currentExplainAbortController.signal
      })
      let result = ''
      
      for await (const chunk of stream) {
        // æ¯ä¸ª chunk æ˜¯å¢é‡å†…å®¹ï¼ˆæ–°å¢çš„ tokenï¼‰ï¼Œéœ€è¦ç´¯ç§¯
        result += chunk
        
        // å¦‚æœæœ‰å›è°ƒï¼Œå®æ—¶æ›´æ–°ç´¯ç§¯ç»“æœ
        if (optsWithDefaults.onChunk) {
          optsWithDefaults.onChunk(result)
        }
      }
      
      console.log('[AI] âœ… Explanation completed')
      console.log('[AI] Result length:', result.length)
      
      return result
    } catch (streamError) {
      console.error('[AI] Streaming error, trying non-streaming approach:', streamError)
      
      // æ£€æŸ¥ session æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
      if (!currentExplainSession) {
        console.error('[AI] Session is null, cannot retry with non-streaming')
        throw streamError
      }
      
      // åˆ›å»ºæ–°çš„ AbortControllerï¼Œé¿å…ä½¿ç”¨å·²ä¸­æ­¢çš„ signal
      const retryAbortController = new AbortController()
      
      try {
        // å¦‚æœæµå¼å¤±è´¥ï¼Œå°è¯•æ‰¹é‡æ¨¡å¼
        const result = await currentExplainSession.prompt(userPrompt, {
          signal: retryAbortController.signal
        })
        optsWithDefaults.onChunk?.(result)
        return result
      } catch (promptError) {
        console.error('[AI] Non-streaming also failed:', promptError)
        throw promptError
      }
    }
  } catch (e: any) {
    console.error('[AI] Explain error:', e)
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯ abort
    if (e.name === 'AbortError') {
      console.log('[AI] Explain was aborted')
      return ''
    }
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯ NotSupportedError
    if (e.name === 'NotSupportedError') {
      const errorMsg = 'âš ï¸ Unsupported input or output detected. Please try different content or check your language settings.'
      console.error('[AI] NotSupportedError:', e.message)
      optsWithDefaults.onChunk?.(errorMsg)
      return errorMsg
    }
    
    // å…¶ä»–é”™è¯¯ä½¿ç”¨é™çº§æ–¹æ¡ˆ
    const fallback = fallbackExplain(term, opts.context)
    optsWithDefaults.onChunk?.(fallback)
    return fallback
  } finally {
    // æ¸…ç†èµ„æº
    destroyExplainSession()
    
    // é‡æ–°åˆ›å»º keepalive session ä¿æŒæ¨¡å‹ ready
    // ä½¿ç”¨ setTimeout é¿å…é˜»å¡å½“å‰æµç¨‹
    setTimeout(() => {
      ensureKeepaliveSession()
    }, 100)
  }
}

// è·å–æˆ–åˆ›å»º LanguageDetector å®ä¾‹
async function getLanguageDetector(): Promise<LanguageDetector | null> {
  try {
    // å¦‚æœå·²æœ‰å®ä¾‹ï¼Œç›´æ¥è¿”å›
    if (languageDetectorInstance) {
      console.log('[AI] Reusing cached LanguageDetector')
      return languageDetectorInstance
    }

    // æ£€æŸ¥ API æ˜¯å¦å­˜åœ¨
    if (!('LanguageDetector' in self)) {
      console.log('[AI] âŒ LanguageDetector API not found')
      return null
    }

    // æ£€æŸ¥å¯ç”¨æ€§
    const availability = await LanguageDetector.availability()
    console.log('[AI] LanguageDetector status:', availability)

    if (availability === 'unavailable') {
      console.log('[AI] âŒ LanguageDetector unavailable')
      return null
    }

    // æ£€æŸ¥ç”¨æˆ·æ¿€æ´»
    if (availability === 'downloadable' && !navigator.userActivation.isActive) {
      console.log('[AI] âš ï¸ LanguageDetector download requires user activation')
      return null
    }

    console.log('[AI] Creating LanguageDetector instance...')
    const detector = await LanguageDetector.create()
    console.log('[AI] âœ… LanguageDetector created successfully')

    // ç¼“å­˜å®ä¾‹
    languageDetectorInstance = detector
    return detector
  } catch (e) {
    console.error('[AI] âŒ Failed to create LanguageDetector:', e)
    return null
  }
}

// æ£€æµ‹æ–‡æœ¬è¯­è¨€
async function detectLanguage(text: string): Promise<string> {
  try {
    const detector = await getLanguageDetector()
    if (!detector) {
      console.log('[AI] Using fallback language detection (en)')
      return 'en'
    }

    const results = await detector.detect(text)
    if (results && results.length > 0) {
      const topResult = results[0]
      console.log('[AI] Detected language:', topResult.detectedLanguage, 'confidence:', topResult.confidence)
      
      // å¦‚æœç½®ä¿¡åº¦ä½äº 0.7ï¼Œä½¿ç”¨è‹±è¯­å…œåº•
      if (topResult.confidence < 0.7) {
        console.log(`[AI] âš ï¸ Low confidence (${topResult.confidence.toFixed(2)}), using fallback language (en)`)
        return 'en'
      }
      
      return topResult.detectedLanguage
    }

    console.log('[AI] No detection result, using fallback (en)')
    return 'en'
  } catch (e) {
    console.error('[AI] Language detection error:', e)
    return 'en'
  }
}

// è·å–æˆ–åˆ›å»º Translator å®ä¾‹
async function getTranslator(sourceLanguage: string, targetLanguage: string): Promise<Translator | null> {
  try {
    // ä½¿ç”¨è¯­è¨€å¯¹ä½œä¸ºç¼“å­˜é”®
    const cacheKey = `${sourceLanguage}-${targetLanguage}`

    // å¦‚æœå·²æœ‰è¯¥è¯­è¨€å¯¹çš„å®ä¾‹ï¼Œç›´æ¥è¿”å›
    if (translatorCache.has(cacheKey)) {
      console.log(`[AI] Reusing cached Translator (${cacheKey})`)
      return translatorCache.get(cacheKey)!
    }

    // æ£€æŸ¥ API æ˜¯å¦å­˜åœ¨
    if (!('Translator' in self)) {
      console.log('[AI] âŒ Translator API not found')
      return null
    }

    // æ£€æŸ¥è¯­è¨€å¯¹å¯ç”¨æ€§
    const availability = await Translator.availability({
      sourceLanguage,
      targetLanguage
    })
    console.log(`[AI] Translator status (${cacheKey}):`, availability)

    if (availability === 'unavailable') {
      console.log(`[AI] âŒ Translator unavailable for ${cacheKey}`)
      return null
    }

    // æ£€æŸ¥ç”¨æˆ·æ¿€æ´»
    if (availability === 'downloadable' && !navigator.userActivation.isActive) {
      console.log('[AI] âš ï¸ Translator download requires user activation')
      return null
    }

    console.log(`[AI] Creating Translator instance (${cacheKey})...`)
    
    const createOptions: TranslatorCreateOptions = {
      sourceLanguage,
      targetLanguage
    }

    // åªæœ‰éœ€è¦ä¸‹è½½æ—¶æ‰æ·»åŠ  monitor
    if (availability === 'downloadable') {
      console.log('[AI] Model needs download - adding progress monitor')
      createOptions.monitor = (m) => {
        m.addEventListener('downloadprogress', (e) => {
          const percent = Math.round(e.loaded * 100)
          console.log(`[AI] Downloading translation model (${cacheKey}): ${percent}%`)
        })
      }
    }

    const translator = await Translator.create(createOptions)
    console.log(`[AI] âœ… Translator created successfully (${cacheKey})`)

    // ç¼“å­˜å®ä¾‹
    translatorCache.set(cacheKey, translator)
    return translator
  } catch (e) {
    console.error('[AI] âŒ Failed to create Translator:', e)
    return null
  }
}

// é™çº§æ–¹æ¡ˆï¼šç®€å•æ ‡è®°
function fallbackTranslate(text: string, targetLang: string): string {
  const troubleshooting = `

âš ï¸ Translation unavailable - AI model not ready. Please refresh the page and try again later.

Quick Setup Guide:
1. Use Chrome 138+ or Chrome Canary/Dev (chrome://version)
2. Enable flags in chrome://flags:
   â€¢ #translation-api â†’ Enabled
   â€¢ #optimization-guide-on-device-model â†’ Enabled BypassPerfRequirement
3. Restart browser
4. Download model at chrome://components (Optimization Guide On Device Model)
5. Requirements: 22GB disk space, 4GB+ GPU or 16GB+ RAM

Learn more: https://developer.chrome.com/docs/ai/built-in-apis`
  
  return `[${targetLang}] ${text}${troubleshooting}`
}

export async function translate(text: string, opts: TransOpts): Promise<string> {
  // é‡ç½®ä¸­æ­¢æ ‡å¿—
  shouldAbortTranslate = false
  
  try {
    console.log('[AI] ===== Translation Request =====')
    console.log('[AI] Target language from settings:', opts.targetLang)

    // 1. æ£€æµ‹æºè¯­è¨€
    console.log('[AI] Detecting source language...')
    const sourceLanguage = await detectLanguage(text)
    console.log(`[AI] Detected source language: ${sourceLanguage}`)

    // 2. å¦‚æœæºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ç›¸åŒï¼Œç›´æ¥è¿”å›
    if (sourceLanguage === opts.targetLang) {
      console.log('[AI] Source and target languages are the same, returning original text')
      opts.onChunk?.(text)
      return text
    }

    // 3. è·å–ç¿»è¯‘å™¨
    console.log(`[AI] Requesting translator for: ${sourceLanguage} -> ${opts.targetLang}`)
    const translator = await getTranslator(sourceLanguage, opts.targetLang)

    if (!translator) {
      console.log('[AI] Using fallback translation')
      const fallback = fallbackTranslate(text, opts.targetLang)
      opts.onChunk?.(fallback)
      return fallback
    }

    // 4. æ‰§è¡Œæµå¼ç¿»è¯‘
    console.log('[AI] Using Chrome AI Translator API (streaming)')

    try {
      const stream = translator.translateStreaming(text)
      let result = ''

      for await (const chunk of stream) {
        // æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»ˆæ­¢
        if (shouldAbortTranslate) {
          console.log('[AI] Translate was aborted')
          return ''
        }
        
        // ç´¯ç§¯å†…å®¹
        result += chunk

        // å®æ—¶æ›´æ–°
        if (opts.onChunk) {
          opts.onChunk(result)
        }
      }

      console.log('[AI] âœ… Translation completed')
      return result
    } catch (streamError) {
      console.error('[AI] Streaming error, trying non-streaming approach:', streamError)
      
      // å¦‚æœå·²ç»è¢«ç»ˆæ­¢ï¼Œç›´æ¥è¿”å›
      if (shouldAbortTranslate) {
        console.log('[AI] Translate was aborted')
        return ''
      }
      
      // å¦‚æœæµå¼å¤±è´¥ï¼Œå°è¯•æ‰¹é‡æ¨¡å¼
      const result = await translator.translate(text)
      opts.onChunk?.(result)
      return result
    }
  } catch (e) {
    console.error('[AI] Translation error:', e)
    const fallback = fallbackTranslate(text, opts.targetLang)
    opts.onChunk?.(fallback)
    return fallback
  }
}

// æ¸…ç†èµ„æº
export function destroyResources() {
  try {
    // æ¸…ç† Summarizer å®ä¾‹
    if (summarizerCache.size > 0) {
      summarizerCache.forEach((summarizer, type) => {
        summarizer.destroy()
        console.log(`[AI] Destroyed Summarizer (type: ${type})`)
      })
      summarizerCache.clear()
      console.log('[AI] All Summarizer instances destroyed')
    }

    // æ¸…ç† Translator å®ä¾‹
    if (translatorCache.size > 0) {
      translatorCache.forEach((translator, langPair) => {
        translator.destroy()
        console.log(`[AI] Destroyed Translator (${langPair})`)
      })
      translatorCache.clear()
      console.log('[AI] All Translator instances destroyed')
    }

    // æ¸…ç† LanguageDetector å®ä¾‹
    if (languageDetectorInstance) {
      languageDetectorInstance.destroy()
      languageDetectorInstance = null
      console.log('[AI] LanguageDetector instance destroyed')
    }

    // ä¸­æ­¢æ‰€æœ‰è¿›è¡Œä¸­çš„æ“ä½œ
    abortSummarize()
    abortTranslate()
    
    // æ¸…ç† Explain session
    destroyExplainSession()
    
    // æ¸…ç† Keepalive session
    destroyKeepaliveSession()
  } catch (e) {
    console.warn('[AI] Error destroying AI instances:', e)
  }
}

